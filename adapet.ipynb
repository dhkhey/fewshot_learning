{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jfTBZn0p_VVw",
    "outputId": "0cf74413-c878-4fc9-ddf5-14d6654e36ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/david/Desktop/fewshot_emotions/ADAPET\n"
     ]
    }
   ],
   "source": [
    "#Go to \"ADAPET\" Directory\n",
    "%cd ADAPET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eKnCGWhNAfLY"
   },
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Environmental Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2YVsFolCBUd6",
    "outputId": "2fb145e2-60b1-4c09-8468-f8394589e14e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: ADAPET_ROOT=/content/drive/MyDrive/ADAPET\n",
      "env: PYTHONPATH=$ADAPET_ROOT:$PYTHONPATH\n",
      "env: PYTHON_EXEC=python\n"
     ]
    }
   ],
   "source": [
    "%env ADAPET_ROOT= /content/drive/MyDrive/ADAPET\n",
    "%env PYTHONPATH=$ADAPET_ROOT:$PYTHONPATH\n",
    "%env PYTHON_EXEC=python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BBIUeIL59kJM"
   },
   "outputs": [],
   "source": [
    "# !rm -r exp_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "gcnXQwqUKxZC"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "zPEzb66Vk1hH"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.txt\", delimiter=';', header=None, names=['sentence','label'])\n",
    "df, _ = train_test_split(df, train_size=0.05,stratify=df['label'],random_state=20)\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# labelencoder = LabelEncoder()\n",
    "# df['label_enc'] = labelencoder.fit_transform(df['label'])\n",
    "df.rename(columns={'sentence':'TEXT1'},inplace=True)\n",
    "df.rename(columns={'label':'LBL'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pTQVFeQslBRH",
    "outputId": "b78a8df5-2084-4602-ee3d-e86ace1e9094"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['anger', 'joy', 'sadness', 'fear', 'love', 'surprise'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['LBL'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "R23JyDO9qHi1"
   },
   "outputs": [],
   "source": [
    "train_df , eval_df = train_test_split(df, train_size=0.6,stratify=df['LBL'],random_state=20)\n",
    "eval_df , test_df = train_test_split(eval_df, train_size=0.6,stratify=eval_df['LBL'],random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "8enxuy0AQ0lr"
   },
   "outputs": [],
   "source": [
    "train_df.to_json('data/my_task/train.jsonl',lines=True,orient='records')\n",
    "test_df.to_json('data/my_task/test.jsonl',lines=True,orient='records')\n",
    "eval_df.to_json('data/my_task/eval.jsonl',lines=True,orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9MKd7FUzY_zp",
    "outputId": "4595ee6a-cc44-436e-b50b-7fdafa307713"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: Tesla T4 (UUID: GPU-2fabe14d-7a70-9249-9aad-523adbb133aa)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SlcPNvQVkCBL"
   },
   "source": [
    "## PROMPT SEARCH\n",
    "You should run evaluations to see which prompt gives best output. Skipped in this notebook due to computation requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "DnEdBMKpZGTs"
   },
   "outputs": [],
   "source": [
    "# skf = StratifiedKFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "dIG0GUAtY_3n"
   },
   "outputs": [],
   "source": [
    "# for train_index, test_index in skf.split(train_df['TEXT1'], train_df['LBL']):\n",
    "    #evaluate here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "LvqsB4wQWul6"
   },
   "outputs": [],
   "source": [
    "# !sh bin/test.sh exp_out/generic/albert-xxlarge-v2/v1f1/\n",
    "# saves = ['v1f1'....]\n",
    "# import pandas as pd\n",
    "# from sklearn.metrics import classification_report\n",
    "# for save in saves:\n",
    "#     predictions = pd.read_json(f\"exp_out/generic/albert-xxlarge-v2/{save}/test.json\",lines=True)\n",
    "#     truth = pd.read_json(\"data/my_task/test.jsonl\",lines=True)\n",
    "#     print(classification_report(list(truth['LBL']),list(predictions['label'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQ2FUdnqk73u"
   },
   "source": [
    "## TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n3WZCu04ZbRr",
    "outputId": "4e1d9814-2caf-4954-859e-a39adaf4534f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RuntimeError: module compiled against API version 0xe but this version of numpy is 0xd\n",
      "Downloading: 100% 710/710 [00:00<00:00, 837kB/s]\n",
      "Downloading: 100% 760k/760k [00:00<00:00, 7.75MB/s]\n",
      "Downloading: 100% 1.31M/1.31M [00:00<00:00, 11.1MB/s]\n",
      "Downloading: 100% 893M/893M [00:24<00:00, 36.5MB/s]\n"
     ]
    }
   ],
   "source": [
    "!python cli.py --data_dir data/my_task --pattern '[TEXT1] The emotion epxressed is [LBL]'  --dict_verbalizer '{\"anger\":\"anger\", \"joy\":\"joy\", \"sadness\":\"sadness\", \"fear\":\"fear\", \"love\":\"love\", \"surprise\":\"surprise\"}' --num_batches 50  --dir_names 'emotion'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rxsiC1FkgwzO",
    "outputId": "bf19da5f-8426-4f53-b8e1-b4a47f96e2fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ exp_dir=exp_out/generic/albert-xxlarge-v2/emotion/\n",
      "+ python -m src.test -e exp_out/generic/albert-xxlarge-v2/emotion/\n",
      "RuntimeError: module compiled against API version 0xe but this version of numpy is 0xd\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.82      0.53      0.64        17\n",
      "        fear       0.67      0.62      0.65        16\n",
      "         joy       0.61      0.88      0.72        43\n",
      "        love       0.67      0.20      0.31        10\n",
      "     sadness       0.67      0.65      0.66        37\n",
      "    surprise       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.65       128\n",
      "   macro avg       0.57      0.48      0.50       128\n",
      "weighted avg       0.64      0.65      0.62       128\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!sh bin/test.sh exp_out/generic/albert-xxlarge-v2/emotion/\n",
    "predictions = pd.read_json(f\"exp_out/generic/albert-xxlarge-v2/emotion/test.json\",lines=True)\n",
    "truth = pd.read_json(\"data/my_task/test.jsonl\",lines=True)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(list(truth['LBL']),list(predictions['label'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LYEMbMkL5akL"
   },
   "source": [
    "The performance is not that great but mainly because I haven't done any validation to find best prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
